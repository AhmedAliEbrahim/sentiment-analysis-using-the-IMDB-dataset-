{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Q7cJwWgon0sOlN-aAbl0T3X-j26iIX7o","authorship_tag":"ABX9TyO0iBHu4EGo3d1UgcDhn7lX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W9BVcUbU-8sw","executionInfo":{"status":"ok","timestamp":1742584697731,"user_tz":-120,"elapsed":843735,"user":{"displayName":"احمد علي","userId":"16809122296572499401"}},"outputId":"2023e95f-aa7a-47e7-9255-4dd1721ea719"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.87\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.87      0.86      0.86      4961\n","           1       0.86      0.88      0.87      5039\n","\n","    accuracy                           0.87     10000\n","   macro avg       0.87      0.87      0.87     10000\n","weighted avg       0.87      0.87      0.87     10000\n","\n"]}],"source":["import pandas as pd\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","nltk.download('stopwords')\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/IMDB Dataset.csv\")\n","\n","def preprocess_text(text):\n","    text = text.lower()\n","    text = re.sub(r\"<.*?>\", \"\", text)\n","    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n","    words = text.split()\n","    words = [word for word in words if word not in stopwords.words('english')]\n","    return \" \".join(words)\n","\n","df['cleaned_review'] = df['review'].apply(preprocess_text)\n","\n","vectorizer = TfidfVectorizer(max_features=1000)\n","X = vectorizer.fit_transform(df['cleaned_review'])\n","\n","y = df['sentiment'].map({'positive': 1, 'negative': 0})\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy:.2f}\")\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"]}]}